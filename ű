\chapter{Results}

\section{Hardware}

I used special hardware for testing the solver's capabilities. 

Here is the specification of the hardware:

The CPU has 32 cores, which allowed me to test for many multithreaded settings.

\begin{lstlisting}
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                32
On-line CPU(s) list:   0-31
Thread(s) per core:    2
Core(s) per socket:    8
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 45
Model name:            Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz
Stepping:              7
CPU MHz:               1200.305
CPU max MHz:           3000,0000
CPU min MHz:           1200,0000
BogoMIPS:              4389.29
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              20480K
NUMA node0 CPU(s):     0-7,16-23
NUMA node1 CPU(s):     8-15,24-31
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep 
                       mtrr pge mca cmov pat pse36 clflush dts acpi mmx
                       fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp
                       lm constant_tsc arch_perfmon pebs bts rep_good nopl
                       xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64
                       monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm
                       pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer
                       aes xsave avx lahf_lm epb kaiser tpr_shadow vnmi
                       flexpriority ept vpid xsaveopt dtherm ida arat pln pts
\end{lstlisting}

It also had a large amount of memory available for use.

\begin{lstlisting}
              total        used        free      shared  buff/cache   available
Mem:           125G        789M        120G        147M        4,1G        123G
Swap:            0B          0B          0B
\end{lstlisting}

\section{Analysis}

I ran the solver for 2 hours on 1,2,4,8,16,32 and 64 threads sequentially.

\begin{figure}[!ht]
\centering
\includegraphics[width=\linewidth, keepaspectratio]{figures/user_time.png}
\caption{Runtime} 
\end{figure}

In the graph above we can see the runtime for the different amount of threads. The X axis represents the number of iterations the solver was able to achieve. The Y axis is the runtime needed for that amount of iterations.

I did run the solver on 1 thread, but it was not able to return a feasible solution, so it is not shown on the graphs.

We can clearly see that 2 threads is really slow, it needs around 5000 seconds for 20 iterations. 4 threads looks better, it was able to run 40 iterations in the same amount of time. 8, 16 and 64 threads achieved the same results. 64 threads is interesting, since it is double the amount of cores in the computer. This clearly shows that when we use more threads than available computing units the context switch takes up a large amount of time, slowing down the entire application.

As we can see, 32 threads performed the best, achieving the most iterations, more than 100 in the given amount of time.

\begin{figure}[!ht]
\centering
\includegraphics[width=\linewidth, keepaspectratio]{figures/optimisation.png}
\caption{Objective} 
\end{figure}

In the graph above we can see the objective achieved for every iteration the solver was able to run. The X axis represents the number of iterations and the Y axis the objective achieved.

As we can see, 2 threads achieved nothing. It was too slow, did not run enough iterations to find better solutions. 4 threads performed better, but still was far from ideal.
8, 16 and 64 threads look the same, 32 performing slightly better, with a better objective as its result.

\section{Summary}

The analysis above demonstrates that the solver benefits from a large number of parallel threads, which means performance and runtime can be boosted by adding more cores to the system. It also shows a basic principle in computing: more threads than cores will result in slower runtimes for all threads.

\chapter{Final words}


The current state of the application is a good start. It is a proof of concept that timetable planning for Budapest University of Technology and Economics could be and should be automated.

In the current state, it will not be able to suit the needs of the faculty. The solver does not schedule exams, it does not take specialisation classes or electives into account. The rooms are only distributed depending on their type (large seminar halls, practice session rooms, laboratories) but there is no way to specify the capacity to account for every student. The client not usable to a non-expert in the current state. It can't account for the requests from the faculty members, such as building preference and their schedules.

In the future, I plan on adding more functionality to this software as part of my master's degree thesis.
